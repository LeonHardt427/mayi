{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.read_csv(\"E:\\\\leonhardt\\\\mayi\\\\data\\\\train.csv\")\n",
    "df_test = pd.read_csv(\"E:\\\\leonhardt\\\\mayi\\\\data\\\\test_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train[\"label\"]!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df_train.describe().loc[\"count\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f45', 'f38', 'f37', 'f36', 'f41', 'f42', 'f43', 'f44', 'f46', 'f47',\n",
       "       'f39', 'f40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = count.sort_values()\n",
    "count_col = count.index[0:12]\n",
    "count_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(count_col, axis=1, inplace=True)\n",
    "df_test.drop(count_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df_train[df_train[\"date\"]<=20171005]\n",
    "eva_set = df_train[df_train[\"date\"]>20171005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_set[\"label\"]\n",
    "eva_label = eva_set[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_set.drop([\"id\", \"label\", \"date\"], axis=1, inplace=True)\n",
    "eva_set.drop([\"id\", \"label\", \"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       ...\n",
       "       'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296',\n",
       "       'f297'],\n",
       "      dtype='object', length=285)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "for col in train_set.columns:\n",
    "    train_set[col].fillna(train_set[col].mean(axis=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "for col in eva_set.columns:\n",
    "    eva_set[col].fillna(eva_set[col].mean(axis=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop([\"id\", \"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    df_test[col].fillna(df_test[col].mean(axis=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt = GradientBoostingClassifier(  \n",
    "    init=None,  \n",
    "    learning_rate=0.05,  \n",
    "    loss='deviance',\n",
    "    max_depth=5,  \n",
    "    max_features=None,  \n",
    "    max_leaf_nodes=None,  \n",
    "    min_samples_leaf=1,  \n",
    "    min_samples_split=2,  \n",
    "    min_weight_fraction_leaf=0.0,  \n",
    "    n_estimators=300,  \n",
    "    random_state=None,  \n",
    "    subsample=1.0,  \n",
    "    verbose=10,  \n",
    "    warm_start=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1025           48.10m\n",
      "         2           0.0987           49.05m\n",
      "         3           0.0958           49.26m\n",
      "         4           0.0932           48.38m\n",
      "         5           0.0911           47.93m\n",
      "         6           0.0894           47.46m\n",
      "         7           0.0876           47.30m\n",
      "         8           0.0862           47.02m\n",
      "         9           0.0847           46.80m\n",
      "        10           0.0834           46.52m\n",
      "        11           0.0823           46.29m\n",
      "        12           0.0812           46.35m\n",
      "        13           0.0802           46.33m\n",
      "        14           0.0785           46.56m\n",
      "        15           0.0773           46.56m\n",
      "        16           0.0759           46.63m\n",
      "        17           0.0746           46.65m\n",
      "        18           0.0734           46.60m\n",
      "        19           0.0724           46.61m\n",
      "        20           0.0713           46.60m\n",
      "        21           0.0704           46.54m\n",
      "        22           0.0696           46.45m\n",
      "        23           0.0688           46.43m\n",
      "        24           0.0682           46.20m\n",
      "        25           0.0674           46.07m\n",
      "        26           0.0667           45.92m\n",
      "        27           0.0661           45.80m\n",
      "        28           0.0656           45.64m\n",
      "        29           0.0648           45.42m\n",
      "        30           0.0643           45.24m\n",
      "        31           0.0637           45.05m\n",
      "        32           0.0631           44.92m\n",
      "        33           0.0626           44.74m\n",
      "        34           0.0621           44.62m\n",
      "        35           0.0617           44.40m\n",
      "        36           0.0614           44.23m\n",
      "        37           0.0610           44.00m\n",
      "        38           0.0606           43.87m\n",
      "        39           0.0602           43.66m\n",
      "        40           0.0598           43.52m\n",
      "        41           0.0595           43.31m\n",
      "        42           0.0590           43.17m\n",
      "        43           0.0585           43.03m\n",
      "        44           0.0581           42.87m\n",
      "        45           0.0576           42.75m\n",
      "        46           0.0573           42.62m\n",
      "        47           0.0571           42.51m\n",
      "        48           0.0567           42.42m\n",
      "        49           0.0565           42.23m\n",
      "        50           0.0562           42.06m\n",
      "        51           0.0560           41.94m\n",
      "        52           0.0555           41.80m\n",
      "        53           0.0552           41.70m\n",
      "        54           0.0550           41.54m\n",
      "        55           0.0546           41.38m\n",
      "        56           0.0543           41.25m\n",
      "        57           0.0541           41.07m\n",
      "        58           0.0539           40.92m\n",
      "        59           0.0536           40.82m\n",
      "        60           0.0533           40.70m\n",
      "        61           0.0530           40.53m\n",
      "        62           0.0529           40.36m\n",
      "        63           0.0527           40.18m\n",
      "        64           0.0525           40.09m\n",
      "        65           0.0523           39.94m\n",
      "        66           0.0521           39.75m\n",
      "        67           0.0520           39.61m\n",
      "        68           0.0518           39.55m\n",
      "        69           0.0516           39.44m\n",
      "        70           0.0514           39.23m\n",
      "        71           0.0512           39.04m\n",
      "        72           0.0510           38.94m\n",
      "        73           0.0508           38.76m\n",
      "        74           0.0507           38.58m\n",
      "        75           0.0505           38.38m\n",
      "        76           0.0505           38.10m\n",
      "        77           0.0504           37.89m\n",
      "        78           0.0502           37.81m\n",
      "        79           0.0501           37.58m\n",
      "        80           0.0500           37.39m\n",
      "        81           0.0498           37.23m\n",
      "        82           0.0497           37.03m\n",
      "        83           0.0497           36.80m\n",
      "        84           0.0496           36.55m\n",
      "        85           0.0495           36.46m\n",
      "        86           0.0494           36.28m\n",
      "        87           0.0493           36.01m\n",
      "        88           0.0492           35.82m\n",
      "        89           0.0491           35.64m\n",
      "        90           0.0491           35.41m\n",
      "        91           0.0489           35.37m\n",
      "        92           0.0489           35.13m\n",
      "        93           0.0486           34.99m\n",
      "        94           0.0485           34.81m\n",
      "        95           0.0484           34.67m\n",
      "        96           0.0484           34.46m\n",
      "        97           0.0483           34.28m\n",
      "        98           0.0483           34.07m\n",
      "        99           0.0482           33.87m\n",
      "       100           0.0481           33.81m\n",
      "       101           0.0480           33.67m\n",
      "       102           0.0480           33.47m\n",
      "       103           0.0479           33.24m\n",
      "       104           0.0479           33.03m\n",
      "       105           0.0478           32.88m\n",
      "       106           0.0477           32.71m\n",
      "       107           0.0476           32.48m\n",
      "       108           0.0476           32.27m\n",
      "       109           0.0476           32.05m\n",
      "       110           0.0475           31.98m\n",
      "       111           0.0473           31.84m\n",
      "       112           0.0472           31.67m\n",
      "       113           0.0472           31.46m\n",
      "       114           0.0471           31.27m\n",
      "       115           0.0470           31.06m\n",
      "       116           0.0470           30.89m\n",
      "       117           0.0469           30.71m\n",
      "       118           0.0468           30.52m\n",
      "       119           0.0467           30.34m\n",
      "       120           0.0467           30.14m\n",
      "       121           0.0466           29.96m\n",
      "       122           0.0466           29.77m\n",
      "       123           0.0465           29.66m\n",
      "       124           0.0464           29.46m\n",
      "       125           0.0463           29.33m\n",
      "       126           0.0462           29.17m\n",
      "       127           0.0462           28.99m\n",
      "       128           0.0461           28.81m\n",
      "       129           0.0460           28.62m\n",
      "       130           0.0460           28.44m\n",
      "       131           0.0459           28.26m\n",
      "       132           0.0459           28.10m\n",
      "       133           0.0458           27.92m\n",
      "       134           0.0457           27.78m\n",
      "       135           0.0456           27.59m\n",
      "       136           0.0456           27.38m\n",
      "       137           0.0455           27.24m\n",
      "       138           0.0454           27.06m\n",
      "       139           0.0453           26.88m\n",
      "       140           0.0453           26.68m\n",
      "       141           0.0452           26.50m\n",
      "       142           0.0452           26.31m\n",
      "       143           0.0452           26.10m\n",
      "       144           0.0452           25.92m\n",
      "       145           0.0449           25.80m\n",
      "       146           0.0448           25.69m\n",
      "       147           0.0447           25.53m\n",
      "       148           0.0446           25.35m\n",
      "       149           0.0446           25.17m\n",
      "       150           0.0446           24.98m\n",
      "       151           0.0445           24.82m\n",
      "       152           0.0445           24.63m\n",
      "       153           0.0444           24.45m\n",
      "       154           0.0444           24.29m\n",
      "       155           0.0443           24.09m\n",
      "       156           0.0443           23.97m\n",
      "       157           0.0442           23.77m\n",
      "       158           0.0442           23.60m\n",
      "       159           0.0441           23.43m\n",
      "       160           0.0441           23.26m\n",
      "       161           0.0440           23.11m\n",
      "       162           0.0440           22.93m\n",
      "       163           0.0439           22.76m\n",
      "       164           0.0439           22.58m\n",
      "       165           0.0438           22.42m\n",
      "       166           0.0438           22.22m\n",
      "       167           0.0437           22.09m\n",
      "       168           0.0437           21.91m\n",
      "       169           0.0436           21.72m\n",
      "       170           0.0436           21.54m\n",
      "       171           0.0435           21.40m\n",
      "       172           0.0435           21.20m\n",
      "       173           0.0434           21.05m\n",
      "       174           0.0433           20.86m\n",
      "       175           0.0433           20.69m\n",
      "       176           0.0433           20.51m\n",
      "       177           0.0433           20.33m\n",
      "       178           0.0432           22.01m\n",
      "       179           0.0432           21.81m\n",
      "       180           0.0431           21.65m\n",
      "       181           0.0431           21.44m\n",
      "       182           0.0430           21.25m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       183           0.0430           21.04m\n",
      "       184           0.0429           20.85m\n",
      "       185           0.0429           20.65m\n",
      "       186           0.0429           20.50m\n",
      "       187           0.0428           20.30m\n",
      "       188           0.0428           20.12m\n",
      "       189           0.0427           19.95m\n",
      "       190           0.0426           19.76m\n",
      "       191           0.0426           19.55m\n",
      "       192           0.0425           19.36m\n",
      "       193           0.0424           19.17m\n",
      "       194           0.0424           18.98m\n",
      "       195           0.0423           18.83m\n",
      "       196           0.0423           18.65m\n",
      "       197           0.0423           18.44m\n",
      "       198           0.0423           18.25m\n",
      "       199           0.0423           18.05m\n",
      "       200           0.0422           17.85m\n",
      "       201           0.0422           17.67m\n",
      "       202           0.0421           17.48m\n",
      "       203           0.0421           17.31m\n",
      "       204           0.0421           17.15m\n",
      "       205           0.0420           16.97m\n",
      "       206           0.0420           16.78m\n",
      "       207           0.0420           16.57m\n",
      "       208           0.0419           16.38m\n",
      "       209           0.0419           16.20m\n",
      "       210           0.0418           16.03m\n",
      "       211           0.0418           15.84m\n",
      "       212           0.0418           15.65m\n",
      "       213           0.0417           15.46m\n",
      "       214           0.0417           15.27m\n",
      "       215           0.0417           15.10m\n",
      "       216           0.0417           14.91m\n",
      "       217           0.0416           14.74m\n",
      "       218           0.0416           14.55m\n",
      "       219           0.0415           14.36m\n",
      "       220           0.0415           14.18m\n",
      "       221           0.0414           14.01m\n",
      "       222           0.0413           13.82m\n",
      "       223           0.0413           13.64m\n",
      "       224           0.0412           13.46m\n",
      "       225           0.0412           13.28m\n",
      "       226           0.0411           13.09m\n",
      "       227           0.0411           12.90m\n",
      "       228           0.0411           12.72m\n",
      "       229           0.0411           12.53m\n",
      "       230           0.0410           12.37m\n",
      "       231           0.0410           12.20m\n",
      "       232           0.0410           12.02m\n",
      "       233           0.0410           11.83m\n",
      "       234           0.0409           11.65m\n",
      "       235           0.0409           11.47m\n",
      "       236           0.0409           11.29m\n",
      "       237           0.0408           11.11m\n",
      "       238           0.0408           10.93m\n",
      "       239           0.0408           10.76m\n",
      "       240           0.0407           10.58m\n",
      "       241           0.0407           10.41m\n",
      "       242           0.0407           10.22m\n",
      "       243           0.0406           10.05m\n",
      "       244           0.0406            9.87m\n",
      "       245           0.0406            9.69m\n",
      "       246           0.0406            9.50m\n",
      "       247           0.0406            9.32m\n",
      "       248           0.0406            9.13m\n",
      "       249           0.0406            8.95m\n",
      "       250           0.0405            8.78m\n",
      "       251           0.0405            8.60m\n",
      "       252           0.0404            8.42m\n",
      "       253           0.0404            8.25m\n",
      "       254           0.0404            8.07m\n",
      "       255           0.0404            7.89m\n",
      "       256           0.0403            7.71m\n",
      "       257           0.0403            7.53m\n",
      "       258           0.0403            7.35m\n",
      "       259           0.0403            7.17m\n",
      "       260           0.0403            7.00m\n",
      "       261           0.0402            6.82m\n",
      "       262           0.0402            6.65m\n",
      "       263           0.0401            6.48m\n",
      "       264           0.0401            6.30m\n",
      "       265           0.0401            6.13m\n",
      "       266           0.0401            5.95m\n",
      "       267           0.0400            5.78m\n",
      "       268           0.0400            5.60m\n",
      "       269           0.0400            5.43m\n",
      "       270           0.0400            5.25m\n",
      "       271           0.0400            5.08m\n",
      "       272           0.0399            4.90m\n",
      "       273           0.0399            4.72m\n",
      "       274           0.0398            4.55m\n",
      "       275           0.0398            4.37m\n",
      "       276           0.0398            4.19m\n",
      "       277           0.0397            4.02m\n",
      "       278           0.0397            3.85m\n",
      "       279           0.0397            3.67m\n",
      "       280           0.0396            3.50m\n",
      "       281           0.0396            3.32m\n",
      "       282           0.0396            3.15m\n",
      "       283           0.0396            2.97m\n",
      "       284           0.0395            2.80m\n",
      "       285           0.0395            2.62m\n",
      "       286           0.0395            2.45m\n",
      "       287           0.0395            2.27m\n",
      "       288           0.0394            2.10m\n",
      "       289           0.0394            1.92m\n",
      "       290           0.0394            1.75m\n",
      "       291           0.0394            1.57m\n",
      "       292           0.0393            1.40m\n",
      "       293           0.0393            1.22m\n",
      "       294           0.0393            1.05m\n",
      "       295           0.0393           52.41s\n",
      "       296           0.0392           41.95s\n",
      "       297           0.0392           31.45s\n",
      "       298           0.0392           20.95s\n",
      "       299           0.0392           10.47s\n",
      "       300           0.0392            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=10,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_prob = gbdt.predict_proba(eva_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def atec_metric(preds, labels):\n",
    "    fpr,tpr,threshhold=roc_curve(labels, preds)\n",
    "    return 'atec_metric', 0.4*tpr[fpr<=0.001][-1] + 0.3*tpr[fpr<=0.005][-1] + 0.3*tpr[fpr<=0.01][-1], True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('atec_metric', 0.292016473942658, True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_score = atec_metric(eva_prob[:, 1], eva_label)\n",
    "eva_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013609447166257503"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_prob[:, 1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.getcwd()+\"/prediction/gbdt_half_mean_300.txt\", eva_prob, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 score is ('atec_metric', 0.3255979724378267, True)\n"
     ]
    }
   ],
   "source": [
    "# df_eval = pd.Series(index=range(10, 380, 30))\n",
    "# for num in range(10, 380, 30):\n",
    "gbdt = GradientBoostingClassifier(  \n",
    "    init=None,  \n",
    "    learning_rate=0.05,  \n",
    "    loss='deviance',\n",
    "    max_depth=5,  \n",
    "    max_features=None,  \n",
    "    max_leaf_nodes=None,  \n",
    "    min_samples_leaf=1,  \n",
    "    min_samples_split=2,  \n",
    "    min_weight_fraction_leaf=0.0,  \n",
    "    n_estimators=160,  \n",
    "    random_state=None,  \n",
    "    subsample=1.0,  \n",
    "    verbose=0,  \n",
    "    warm_start=False)  \n",
    "gbdt.fit(train_set, train_label)\n",
    "eva_prob = gbdt.predict_proba(eva_set)\n",
    "eva_score = atec_metric(eva_prob[:, 1], eva_label)\n",
    "print(\"{0} score is {1}\".format(160, eva_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gbdt.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.getcwd()+\"/prediction/gbdt_half_mean_160.txt\", y_preds, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
